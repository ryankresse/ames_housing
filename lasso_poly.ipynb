{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import skew\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import warnings\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_clean = pd.read_csv('train_clean.csv', dtype={'MSSubClass': str})  \n",
    "train = pd.read_csv('train.csv', dtype={'MSSubClass': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coef_df = pd.read_csv('coef_df.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove outlier records we previously identified as being harmful to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_clean = train_clean[(train_clean.Id != 1299) & (train_clean.Id != 524)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train_clean['SalePrice']\n",
    "train_clean = train_clean.drop(['SalePrice', 'Id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_expand = list(coef_df.feature[:30].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_no_expand = train_clean.drop(to_expand, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_to_expand = train_clean[to_expand]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "train_to_expand = poly.fit_transform(train_to_expand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.hstack([train_to_expand, train_no_expand.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1458, 886)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#X_train = train_clean.drop(['SalePrice', 'Id'], axis=1)\n",
    "pca = PCA()\n",
    "pca.fit(to_expand)\n",
    "\n",
    "ratios = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "ratios[ratios < 0.98].shape\n",
    "\n",
    "pca = PCA(100)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "\n",
    "\n",
    "feat_cols = coef_df.feature.values[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kf = KFold(len(X_train), 4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.06738257733913645\n",
      "val_score score: 0.07205926037681104\n",
      "train score: 0.06352207689177738\n",
      "val_score score: 0.08151550546928997\n",
      "train score: 0.06474725668629422\n",
      "val_score score: 0.08095462131958743\n",
      "train score: 0.06700755169456961\n",
      "val_score score: 0.07371962799507446\n",
      "mean val error: 0.07706225379019073\n",
      "mean train error: 0.06566486565294442\n"
     ]
    }
   ],
   "source": [
    "val_idx_list = []\n",
    "val_preds = []\n",
    "train_preds = []\n",
    "val_errors = []\n",
    "train_rmse = []\n",
    "val_rmse = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for tr_idx, val_idx in kf:\n",
    "    X_tr, y_tr = X_train[tr_idx, :], y_train.iloc[tr_idx]\n",
    "    X_val, y_val = X_train[val_idx, :], y_train.iloc[val_idx]\n",
    "    val_idx_list.append(val_idx)\n",
    "    ls = Lasso(alpha=.001, max_iter=10000) #the hyperparameter we found to be best\n",
    "    ls.fit(X_tr, y_tr)\n",
    "    preds = ls.predict(X_val)\n",
    "    val_preds.append(preds)\n",
    "    val_errors.append(np.abs(y_val.values - preds))\n",
    "    tr_preds = ls.predict(X_tr)\n",
    "    train_preds.append(tr_preds)\n",
    "    train_score = np.mean(np.sqrt((y_tr.values - tr_preds)**2))\n",
    "    train_rmse.append(train_score)\n",
    "    print('train score: {}'.format(train_score))\n",
    "    val_score = np.mean(np.sqrt((y_val.values - preds)**2))\n",
    "    val_rmse.append(val_score)\n",
    "    print('val_score score: {}'.format(val_score))\n",
    "    \n",
    "print(\"mean val error: {}\".format(np.mean(val_rmse)))\n",
    "print(\"mean train error: {}\".format(np.mean(train_rmse)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run grid search to fit find the best shrinkage hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def runGSAndGetRMSE(est, params):\n",
    "    gs = GridSearchCV(est, param_grid= params, scoring='neg_mean_squared_error')\n",
    "    gs.fit(X_train, y_train)\n",
    "    rmse = np.mean(np.sqrt(-cross_val_score(gs.best_estimator_, X_train,y_train, scoring=\"neg_mean_squared_error\", cv = 5))) \n",
    "    print('mean rmse: {}'.format(rmse))\n",
    "    print('best alpha: {}'.format(gs.best_params_['alpha']))\n",
    "    return gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean rmse: 0.11195550003012626\n",
      "best alpha: 0.001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lassoParams = {'alpha': [0.001, .01, 0.1]}\n",
    "bestLassoEst = runGSAndGetRMSE(Lasso(max_iter=10000), lassoParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit our tuned model on all the data prior to submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=10000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestLassoEst.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on the test set and undo our log transform so that the values will be on their original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_clean.csv', dtype={'MSSubClass': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = test.Id.values\n",
    "test = test.drop('Id', axis=1)\n",
    "test_to_expand = test[to_expand]\n",
    "test_to_expand = poly.transform(test_to_expand)\n",
    "test = test.drop(to_expand, axis=1)\n",
    "\n",
    "test = np.hstack([test_to_expand, test.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = np.expm1(bestLassoEst.predict(test))\n",
    "solution = pd.DataFrame({\"id\":ids, \"SalePrice\":preds}, columns=['id', 'SalePrice'])\n",
    "\n",
    "solution.to_csv(\"lasso_expand_35.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one scores .12046"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the model so we can use it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poly_features_35_2.pkl']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(bestLassoEst, 'poly_features_35_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
