{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryanryanadmin/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import skew\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import warnings\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_clean = pd.read_csv('train_clean.csv', dtype={'MSSubClass': str})  \n",
    "train = pd.read_csv('train.csv', dtype={'MSSubClass': str})\n",
    "test = pd.read_csv('test.csv', dtype={'MSSubClass': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train[(train.Id != 1299) & (train.Id != 524)]\n",
    "all_data = pd.concat([train,\n",
    "                      test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fill_with_zero = [ \n",
    "    'LotFrontage',\n",
    "    'MasVnrArea',\n",
    "    'GarageCars',\n",
    "    'TotalBsmtSF',\n",
    "    'BsmtFullBath',\n",
    "    'BsmtHalfBath',\n",
    "    'BsmtFinSF1', \n",
    "    'BsmtFinSF2',\n",
    "    'BsmtUnfSF',\n",
    "    'GarageArea'\n",
    "  ]\n",
    "\n",
    "fill_with_most_common = [\n",
    "    'Electrical'\n",
    "]\n",
    "\n",
    "fill_with_none = [\n",
    "    'FireplaceQu',      \n",
    "    'GarageType',   \n",
    "    'GarageYrBlt',      \n",
    "    'GarageFinish',     \n",
    "    'GarageQual',       \n",
    "    'GarageCond',       \n",
    "    'PoolQC',          \n",
    "    'Fence',\n",
    "    'MiscFeature', \n",
    "    'BsmtQual',   \n",
    "    'BsmtCond',          \n",
    "    'BsmtExposure',      \n",
    "    'BsmtFinType1',      \n",
    "    'BsmtFinType2',\n",
    "    'MasVnrType',\n",
    "    'Alley'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def prepData(df, unskew=False):\n",
    "    dfForModel = df.copy()\n",
    "    \n",
    "    for col in fill_with_zero:\n",
    "        dfForModel[col] = dfForModel[col].fillna(0)\n",
    "    \n",
    "    for col in fill_with_none:\n",
    "        dfForModel[col] = dfForModel[col].fillna('None')\n",
    "    \n",
    "    for col in fill_with_most_common:\n",
    "        dfForModel[col] = dfForModel[col].fillna(train[col].value_counts().index[0])\n",
    "        \n",
    "    \n",
    "    \n",
    "    numeric_feats = dfForModel.dtypes[dfForModel.dtypes != 'object'].index\n",
    "    numeric_feats = [feat for feat in numeric_feats if feat != 'SalePrice' and feat !='Id' and feat !='YrSold']\n",
    "    '''\n",
    "    if unskew:\n",
    "        skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
    "        skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "        skewed_feats = skewed_feats.index\n",
    "        dfForModel[skewed_feats] = np.log1p(dfForModel[skewed_feats])\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    dfForModel[numeric_feats] = sc.fit_transform(dfForModel[numeric_feats])\n",
    "    '''\n",
    "    \n",
    "    dfForModel[\"SalePrice\"] = np.log1p(dfForModel[\"SalePrice\"])\n",
    "    return pd.get_dummies(dfForModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1458, 420)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_prepped = prepData(all_data, unskew=True)\n",
    "X_train = all_data_prepped[:train.shape[0]].drop('SalePrice', axis=1)\n",
    "X_test = all_data_prepped[train.shape[0]:].drop('SalePrice', axis=1)\n",
    "y = all_data_prepped[:train.shape[0]].SalePrice\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtr = xgb.DMatrix(X_train, label = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- .1 - 350, .1293\n",
    "- .3 .14\n",
    "- .05 = .126 - 471"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.955692</td>\n",
       "      <td>0.008046</td>\n",
       "      <td>10.955695</td>\n",
       "      <td>0.003716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.409218</td>\n",
       "      <td>0.008223</td>\n",
       "      <td>10.409220</td>\n",
       "      <td>0.003513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.890078</td>\n",
       "      <td>0.008387</td>\n",
       "      <td>9.890080</td>\n",
       "      <td>0.003319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.396910</td>\n",
       "      <td>0.008542</td>\n",
       "      <td>9.396912</td>\n",
       "      <td>0.003135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.928418</td>\n",
       "      <td>0.008687</td>\n",
       "      <td>8.928420</td>\n",
       "      <td>0.002958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.483372</td>\n",
       "      <td>0.008822</td>\n",
       "      <td>8.483374</td>\n",
       "      <td>0.002789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.060522</td>\n",
       "      <td>0.008851</td>\n",
       "      <td>8.060597</td>\n",
       "      <td>0.002639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.658879</td>\n",
       "      <td>0.008882</td>\n",
       "      <td>7.658954</td>\n",
       "      <td>0.002503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.277305</td>\n",
       "      <td>0.008917</td>\n",
       "      <td>7.277379</td>\n",
       "      <td>0.002374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.914800</td>\n",
       "      <td>0.008953</td>\n",
       "      <td>6.914873</td>\n",
       "      <td>0.002251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6.569972</td>\n",
       "      <td>0.008911</td>\n",
       "      <td>6.570483</td>\n",
       "      <td>0.002139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.243141</td>\n",
       "      <td>0.008649</td>\n",
       "      <td>6.243293</td>\n",
       "      <td>0.002030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.931925</td>\n",
       "      <td>0.008651</td>\n",
       "      <td>5.932459</td>\n",
       "      <td>0.001929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.636979</td>\n",
       "      <td>0.008379</td>\n",
       "      <td>5.637155</td>\n",
       "      <td>0.001831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.356422</td>\n",
       "      <td>0.008354</td>\n",
       "      <td>5.356616</td>\n",
       "      <td>0.001743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.089764</td>\n",
       "      <td>0.008122</td>\n",
       "      <td>5.090099</td>\n",
       "      <td>0.001656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.836552</td>\n",
       "      <td>0.007796</td>\n",
       "      <td>4.836907</td>\n",
       "      <td>0.001577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.596243</td>\n",
       "      <td>0.007761</td>\n",
       "      <td>4.596373</td>\n",
       "      <td>0.001503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.367555</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>4.367866</td>\n",
       "      <td>0.001434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.150775</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>4.150784</td>\n",
       "      <td>0.001369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.944291</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>3.944564</td>\n",
       "      <td>0.001312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.748236</td>\n",
       "      <td>0.007861</td>\n",
       "      <td>3.748664</td>\n",
       "      <td>0.001259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.562227</td>\n",
       "      <td>0.007891</td>\n",
       "      <td>3.562566</td>\n",
       "      <td>0.001209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.385732</td>\n",
       "      <td>0.007707</td>\n",
       "      <td>3.385783</td>\n",
       "      <td>0.001165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.217824</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>3.217832</td>\n",
       "      <td>0.001122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.058317</td>\n",
       "      <td>0.008059</td>\n",
       "      <td>3.058291</td>\n",
       "      <td>0.001078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.906690</td>\n",
       "      <td>0.008278</td>\n",
       "      <td>2.906717</td>\n",
       "      <td>0.001034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.762900</td>\n",
       "      <td>0.007939</td>\n",
       "      <td>2.762724</td>\n",
       "      <td>0.000990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.626211</td>\n",
       "      <td>0.007779</td>\n",
       "      <td>2.625943</td>\n",
       "      <td>0.000952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.496224</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>2.495988</td>\n",
       "      <td>0.000934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>0.126858</td>\n",
       "      <td>0.005276</td>\n",
       "      <td>0.017826</td>\n",
       "      <td>0.002290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>0.126862</td>\n",
       "      <td>0.005267</td>\n",
       "      <td>0.017726</td>\n",
       "      <td>0.002259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0.126866</td>\n",
       "      <td>0.005269</td>\n",
       "      <td>0.017686</td>\n",
       "      <td>0.002259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0.126863</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>0.017650</td>\n",
       "      <td>0.002251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0.126861</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>0.017593</td>\n",
       "      <td>0.002259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>0.126861</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0.017546</td>\n",
       "      <td>0.002252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.126851</td>\n",
       "      <td>0.005267</td>\n",
       "      <td>0.017486</td>\n",
       "      <td>0.002216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.126848</td>\n",
       "      <td>0.005267</td>\n",
       "      <td>0.017445</td>\n",
       "      <td>0.002193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>0.126848</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.017406</td>\n",
       "      <td>0.002187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>0.126848</td>\n",
       "      <td>0.005272</td>\n",
       "      <td>0.017342</td>\n",
       "      <td>0.002200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>0.126855</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>0.017268</td>\n",
       "      <td>0.002202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0.126846</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.017216</td>\n",
       "      <td>0.002193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0.126846</td>\n",
       "      <td>0.005275</td>\n",
       "      <td>0.017168</td>\n",
       "      <td>0.002191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>0.126851</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>0.017118</td>\n",
       "      <td>0.002202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>0.126850</td>\n",
       "      <td>0.005279</td>\n",
       "      <td>0.017057</td>\n",
       "      <td>0.002209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0.126852</td>\n",
       "      <td>0.005275</td>\n",
       "      <td>0.017018</td>\n",
       "      <td>0.002203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>0.126860</td>\n",
       "      <td>0.005269</td>\n",
       "      <td>0.016964</td>\n",
       "      <td>0.002173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0.126864</td>\n",
       "      <td>0.005276</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>0.002177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0.126857</td>\n",
       "      <td>0.005285</td>\n",
       "      <td>0.016845</td>\n",
       "      <td>0.002150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0.126864</td>\n",
       "      <td>0.005280</td>\n",
       "      <td>0.016766</td>\n",
       "      <td>0.002138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0.126869</td>\n",
       "      <td>0.005272</td>\n",
       "      <td>0.016736</td>\n",
       "      <td>0.002135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>0.126868</td>\n",
       "      <td>0.005275</td>\n",
       "      <td>0.016688</td>\n",
       "      <td>0.002090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>0.126858</td>\n",
       "      <td>0.005276</td>\n",
       "      <td>0.016649</td>\n",
       "      <td>0.002085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>0.126853</td>\n",
       "      <td>0.005276</td>\n",
       "      <td>0.016628</td>\n",
       "      <td>0.002083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>0.126845</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>0.016592</td>\n",
       "      <td>0.002084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>0.126842</td>\n",
       "      <td>0.005290</td>\n",
       "      <td>0.016553</td>\n",
       "      <td>0.002066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>0.126855</td>\n",
       "      <td>0.005288</td>\n",
       "      <td>0.016502</td>\n",
       "      <td>0.002078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>0.126855</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>0.016468</td>\n",
       "      <td>0.002076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0.126844</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>0.016424</td>\n",
       "      <td>0.002084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>0.126834</td>\n",
       "      <td>0.005281</td>\n",
       "      <td>0.016354</td>\n",
       "      <td>0.002100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     test-rmse-mean  test-rmse-std  train-rmse-mean  train-rmse-std\n",
       "0         10.955692       0.008046        10.955695        0.003716\n",
       "1         10.409218       0.008223        10.409220        0.003513\n",
       "2          9.890078       0.008387         9.890080        0.003319\n",
       "3          9.396910       0.008542         9.396912        0.003135\n",
       "4          8.928418       0.008687         8.928420        0.002958\n",
       "5          8.483372       0.008822         8.483374        0.002789\n",
       "6          8.060522       0.008851         8.060597        0.002639\n",
       "7          7.658879       0.008882         7.658954        0.002503\n",
       "8          7.277305       0.008917         7.277379        0.002374\n",
       "9          6.914800       0.008953         6.914873        0.002251\n",
       "10         6.569972       0.008911         6.570483        0.002139\n",
       "11         6.243141       0.008649         6.243293        0.002030\n",
       "12         5.931925       0.008651         5.932459        0.001929\n",
       "13         5.636979       0.008379         5.637155        0.001831\n",
       "14         5.356422       0.008354         5.356616        0.001743\n",
       "15         5.089764       0.008122         5.090099        0.001656\n",
       "16         4.836552       0.007796         4.836907        0.001577\n",
       "17         4.596243       0.007761         4.596373        0.001503\n",
       "18         4.367555       0.008065         4.367866        0.001434\n",
       "19         4.150775       0.007874         4.150784        0.001369\n",
       "20         3.944291       0.007880         3.944564        0.001312\n",
       "21         3.748236       0.007861         3.748664        0.001259\n",
       "22         3.562227       0.007891         3.562566        0.001209\n",
       "23         3.385732       0.007707         3.385783        0.001165\n",
       "24         3.217824       0.007949         3.217832        0.001122\n",
       "25         3.058317       0.008059         3.058291        0.001078\n",
       "26         2.906690       0.008278         2.906717        0.001034\n",
       "27         2.762900       0.007939         2.762724        0.000990\n",
       "28         2.626211       0.007779         2.625943        0.000952\n",
       "29         2.496224       0.007182         2.495988        0.000934\n",
       "..              ...            ...              ...             ...\n",
       "433        0.126858       0.005276         0.017826        0.002290\n",
       "434        0.126862       0.005267         0.017726        0.002259\n",
       "435        0.126866       0.005269         0.017686        0.002259\n",
       "436        0.126863       0.005273         0.017650        0.002251\n",
       "437        0.126861       0.005273         0.017593        0.002259\n",
       "438        0.126861       0.005274         0.017546        0.002252\n",
       "439        0.126851       0.005267         0.017486        0.002216\n",
       "440        0.126848       0.005267         0.017445        0.002193\n",
       "441        0.126848       0.005268         0.017406        0.002187\n",
       "442        0.126848       0.005272         0.017342        0.002200\n",
       "443        0.126855       0.005277         0.017268        0.002202\n",
       "444        0.126846       0.005271         0.017216        0.002193\n",
       "445        0.126846       0.005275         0.017168        0.002191\n",
       "446        0.126851       0.005277         0.017118        0.002202\n",
       "447        0.126850       0.005279         0.017057        0.002209\n",
       "448        0.126852       0.005275         0.017018        0.002203\n",
       "449        0.126860       0.005269         0.016964        0.002173\n",
       "450        0.126864       0.005276         0.016908        0.002177\n",
       "451        0.126857       0.005285         0.016845        0.002150\n",
       "452        0.126864       0.005280         0.016766        0.002138\n",
       "453        0.126869       0.005272         0.016736        0.002135\n",
       "454        0.126868       0.005275         0.016688        0.002090\n",
       "455        0.126858       0.005276         0.016649        0.002085\n",
       "456        0.126853       0.005276         0.016628        0.002083\n",
       "457        0.126845       0.005283         0.016592        0.002084\n",
       "458        0.126842       0.005290         0.016553        0.002066\n",
       "459        0.126855       0.005288         0.016502        0.002078\n",
       "460        0.126855       0.005286         0.016468        0.002076\n",
       "461        0.126844       0.005283         0.016424        0.002084\n",
       "462        0.126834       0.005281         0.016354        0.002100\n",
       "\n",
       "[463 rows x 4 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'eta':0.05}\n",
    "num_rounds = 1000\n",
    "early_stopping_rounds = 20\n",
    "xgb.cv(params, dtr,num_rounds, early_stopping_rounds=early_stopping_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_depth:3\n",
    "min_child_weight:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] max_depth=2, min_child_weight=1 .................................\n",
      "[CV] ........ max_depth=2, min_child_weight=1, score=0.919168 -   1.4s\n",
      "[CV] max_depth=2, min_child_weight=1 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ max_depth=2, min_child_weight=1, score=0.896272 -   1.3s\n",
      "[CV] max_depth=2, min_child_weight=1 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ max_depth=2, min_child_weight=1, score=0.890563 -   1.3s\n",
      "[CV] max_depth=2, min_child_weight=3 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ max_depth=2, min_child_weight=3, score=0.921830 -   1.2s\n",
      "[CV] max_depth=2, min_child_weight=3 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    5.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ max_depth=2, min_child_weight=3, score=0.896802 -   1.3s\n",
      "[CV] max_depth=2, min_child_weight=3 .................................\n",
      "[CV] ........ max_depth=2, min_child_weight=3, score=0.907761 -   1.3s\n",
      "[CV] max_depth=2, min_child_weight=5 .................................\n",
      "[CV] ........ max_depth=2, min_child_weight=5, score=0.921257 -   1.3s\n",
      "[CV] max_depth=2, min_child_weight=5 .................................\n",
      "[CV] ........ max_depth=2, min_child_weight=5, score=0.896601 -   1.3s\n",
      "[CV] max_depth=2, min_child_weight=5 .................................\n",
      "[CV] ........ max_depth=2, min_child_weight=5, score=0.910504 -   1.3s\n",
      "[CV] max_depth=4, min_child_weight=1 .................................\n",
      "[CV] ........ max_depth=4, min_child_weight=1, score=0.915387 -   2.3s\n",
      "[CV] max_depth=4, min_child_weight=1 .................................\n",
      "[CV] ........ max_depth=4, min_child_weight=1, score=0.893373 -   3.2s\n",
      "[CV] max_depth=4, min_child_weight=1 .................................\n",
      "[CV] ........ max_depth=4, min_child_weight=1, score=0.905394 -   3.1s\n",
      "[CV] max_depth=4, min_child_weight=3 .................................\n",
      "[CV] ........ max_depth=4, min_child_weight=3, score=0.917854 -   3.2s\n",
      "[CV] max_depth=4, min_child_weight=3 .................................\n",
      "[CV] ........ max_depth=4, min_child_weight=3, score=0.897863 -   2.3s\n",
      "[CV] max_depth=4, min_child_weight=3 .................................\n",
      "[CV] ........ max_depth=4, min_child_weight=3, score=0.898898 -   2.3s\n",
      "[CV] max_depth=4, min_child_weight=5 .................................\n",
      "[CV] ........ max_depth=4, min_child_weight=5, score=0.917768 -   2.7s\n",
      "[CV] max_depth=4, min_child_weight=5 .................................\n",
      "[CV] ........ max_depth=4, min_child_weight=5, score=0.898945 -   2.3s\n",
      "[CV] max_depth=4, min_child_weight=5 .................................\n",
      "[CV] ........ max_depth=4, min_child_weight=5, score=0.913724 -   2.3s\n",
      "[CV] max_depth=6, min_child_weight=1 .................................\n",
      "[CV] ........ max_depth=6, min_child_weight=1, score=0.913201 -   3.9s\n",
      "[CV] max_depth=6, min_child_weight=1 .................................\n",
      "[CV] ........ max_depth=6, min_child_weight=1, score=0.885192 -   3.3s\n",
      "[CV] max_depth=6, min_child_weight=1 .................................\n",
      "[CV] ........ max_depth=6, min_child_weight=1, score=0.902700 -   5.1s\n",
      "[CV] max_depth=6, min_child_weight=3 .................................\n",
      "[CV] ........ max_depth=6, min_child_weight=3, score=0.914772 -   3.3s\n",
      "[CV] max_depth=6, min_child_weight=3 .................................\n",
      "[CV] ........ max_depth=6, min_child_weight=3, score=0.897294 -   4.7s\n",
      "[CV] max_depth=6, min_child_weight=3 .................................\n",
      "[CV] ........ max_depth=6, min_child_weight=3, score=0.906983 -   4.7s\n",
      "[CV] max_depth=6, min_child_weight=5 .................................\n",
      "[CV] ........ max_depth=6, min_child_weight=5, score=0.917421 -   4.3s\n",
      "[CV] max_depth=6, min_child_weight=5 .................................\n",
      "[CV] ........ max_depth=6, min_child_weight=5, score=0.895770 -   4.1s\n",
      "[CV] max_depth=6, min_child_weight=5 .................................\n",
      "[CV] ........ max_depth=6, min_child_weight=5, score=0.909668 -   4.0s\n",
      "[CV] max_depth=8, min_child_weight=1 .................................\n",
      "[CV] ........ max_depth=8, min_child_weight=1, score=0.905308 -   5.5s\n",
      "[CV] max_depth=8, min_child_weight=1 .................................\n",
      "[CV] ........ max_depth=8, min_child_weight=1, score=0.884780 -   4.9s\n",
      "[CV] max_depth=8, min_child_weight=1 .................................\n",
      "[CV] ........ max_depth=8, min_child_weight=1, score=0.889675 -   4.8s\n",
      "[CV] max_depth=8, min_child_weight=3 .................................\n",
      "[CV] ........ max_depth=8, min_child_weight=3, score=0.914417 -   4.6s\n",
      "[CV] max_depth=8, min_child_weight=3 .................................\n",
      "[CV] ........ max_depth=8, min_child_weight=3, score=0.891879 -   4.5s\n",
      "[CV] max_depth=8, min_child_weight=3 .................................\n",
      "[CV] ........ max_depth=8, min_child_weight=3, score=0.899772 -   4.8s\n",
      "[CV] max_depth=8, min_child_weight=5 .................................\n",
      "[CV] ........ max_depth=8, min_child_weight=5, score=0.917201 -   4.4s\n",
      "[CV] max_depth=8, min_child_weight=5 .................................\n",
      "[CV] ........ max_depth=8, min_child_weight=5, score=0.892637 -   4.3s\n",
      "[CV] max_depth=8, min_child_weight=5 .................................\n",
      "[CV] ........ max_depth=8, min_child_weight=5, score=0.908888 -   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.90200, std: 0.01236, params: {'max_depth': 2, 'min_child_weight': 1},\n",
       "  mean: 0.90880, std: 0.01024, params: {'max_depth': 2, 'min_child_weight': 3},\n",
       "  mean: 0.90945, std: 0.01009, params: {'max_depth': 2, 'min_child_weight': 5},\n",
       "  mean: 0.90472, std: 0.00900, params: {'max_depth': 4, 'min_child_weight': 1},\n",
       "  mean: 0.90487, std: 0.00919, params: {'max_depth': 4, 'min_child_weight': 3},\n",
       "  mean: 0.91015, std: 0.00809, params: {'max_depth': 4, 'min_child_weight': 5},\n",
       "  mean: 0.90036, std: 0.01155, params: {'max_depth': 6, 'min_child_weight': 1},\n",
       "  mean: 0.90635, std: 0.00715, params: {'max_depth': 6, 'min_child_weight': 3},\n",
       "  mean: 0.90762, std: 0.00896, params: {'max_depth': 6, 'min_child_weight': 5},\n",
       "  mean: 0.89325, std: 0.00875, params: {'max_depth': 8, 'min_child_weight': 1},\n",
       "  mean: 0.90202, std: 0.00934, params: {'max_depth': 8, 'min_child_weight': 3},\n",
       "  mean: 0.90624, std: 0.01020, params: {'max_depth': 8, 'min_child_weight': 5}],\n",
       " {'max_depth': 4, 'min_child_weight': 5},\n",
       " 0.910145723465552)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':list(range(2,10,2)),\n",
    " 'min_child_weight':list(range(1,6,2))\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBRegressor( learning_rate =0.05, n_estimators=462, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, verbose=5, iid=False, cv=3)\n",
    "gsearch1.fit(X_train ,y)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] max_depth=3, min_child_weight=4 .................................\n",
      "[CV] ........ max_depth=3, min_child_weight=4, score=0.920658 -   1.8s\n",
      "[CV] max_depth=3, min_child_weight=4 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ max_depth=3, min_child_weight=4, score=0.897351 -   1.8s\n",
      "[CV] max_depth=3, min_child_weight=4 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ max_depth=3, min_child_weight=4, score=0.913027 -   1.7s\n",
      "[CV] max_depth=3, min_child_weight=5 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ max_depth=3, min_child_weight=5, score=0.918917 -   1.8s\n",
      "[CV] max_depth=3, min_child_weight=5 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    7.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ max_depth=3, min_child_weight=5, score=0.897429 -   1.7s\n",
      "[CV] max_depth=3, min_child_weight=5 .................................\n",
      "[CV] ........ max_depth=3, min_child_weight=5, score=0.911642 -   1.7s\n",
      "[CV] max_depth=3, min_child_weight=6 .................................\n",
      "[CV] ........ max_depth=3, min_child_weight=6, score=0.919662 -   1.8s\n",
      "[CV] max_depth=3, min_child_weight=6 .................................\n",
      "[CV] ........ max_depth=3, min_child_weight=6, score=0.893742 -   2.3s\n",
      "[CV] max_depth=3, min_child_weight=6 .................................\n",
      "[CV] ........ max_depth=3, min_child_weight=6, score=0.909900 -   2.3s\n",
      "[CV] max_depth=4, min_child_weight=4 .................................\n",
      "[CV] ........ max_depth=4, min_child_weight=4, score=0.918819 -   2.3s\n",
      "[CV] max_depth=4, min_child_weight=4 .................................\n",
      "[CV] ........ max_depth=4, min_child_weight=4, score=0.898974 -   2.7s\n",
      "[CV] max_depth=4, min_child_weight=4 .................................\n",
      "[CV] ........ max_depth=4, min_child_weight=4, score=0.913656 -   3.3s\n",
      "[CV] max_depth=4, min_child_weight=5 .................................\n",
      "[CV] ........ max_depth=4, min_child_weight=5, score=0.917768 -   2.8s\n",
      "[CV] max_depth=4, min_child_weight=5 .................................\n",
      "[CV] ........ max_depth=4, min_child_weight=5, score=0.898945 -   2.3s\n",
      "[CV] max_depth=4, min_child_weight=5 .................................\n",
      "[CV] ........ max_depth=4, min_child_weight=5, score=0.913724 -   3.0s\n",
      "[CV] max_depth=4, min_child_weight=6 .................................\n",
      "[CV] ........ max_depth=4, min_child_weight=6, score=0.919629 -   2.3s\n",
      "[CV] max_depth=4, min_child_weight=6 .................................\n",
      "[CV] ........ max_depth=4, min_child_weight=6, score=0.895903 -   2.5s\n",
      "[CV] max_depth=4, min_child_weight=6 .................................\n",
      "[CV] ........ max_depth=4, min_child_weight=6, score=0.913126 -   3.9s\n",
      "[CV] max_depth=5, min_child_weight=4 .................................\n",
      "[CV] ........ max_depth=5, min_child_weight=4, score=0.918269 -   3.3s\n",
      "[CV] max_depth=5, min_child_weight=4 .................................\n",
      "[CV] ........ max_depth=5, min_child_weight=4, score=0.897648 -   2.8s\n",
      "[CV] max_depth=5, min_child_weight=4 .................................\n",
      "[CV] ........ max_depth=5, min_child_weight=4, score=0.912344 -   3.2s\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV] ........ max_depth=5, min_child_weight=5, score=0.918301 -   2.8s\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV] ........ max_depth=5, min_child_weight=5, score=0.897094 -   3.9s\n",
      "[CV] max_depth=5, min_child_weight=5 .................................\n",
      "[CV] ........ max_depth=5, min_child_weight=5, score=0.912241 -   2.9s\n",
      "[CV] max_depth=5, min_child_weight=6 .................................\n",
      "[CV] ........ max_depth=5, min_child_weight=6, score=0.919106 -   3.2s\n",
      "[CV] max_depth=5, min_child_weight=6 .................................\n",
      "[CV] ........ max_depth=5, min_child_weight=6, score=0.892169 -   2.8s\n",
      "[CV] max_depth=5, min_child_weight=6 .................................\n",
      "[CV] ........ max_depth=5, min_child_weight=6, score=0.912985 -   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.91034, std: 0.00970, params: {'max_depth': 3, 'min_child_weight': 4},\n",
       "  mean: 0.90933, std: 0.00892, params: {'max_depth': 3, 'min_child_weight': 5},\n",
       "  mean: 0.90777, std: 0.01069, params: {'max_depth': 3, 'min_child_weight': 6},\n",
       "  mean: 0.91048, std: 0.00841, params: {'max_depth': 4, 'min_child_weight': 4},\n",
       "  mean: 0.91015, std: 0.00809, params: {'max_depth': 4, 'min_child_weight': 5},\n",
       "  mean: 0.90955, std: 0.01001, params: {'max_depth': 4, 'min_child_weight': 6},\n",
       "  mean: 0.90942, std: 0.00867, params: {'max_depth': 5, 'min_child_weight': 4},\n",
       "  mean: 0.90921, std: 0.00892, params: {'max_depth': 5, 'min_child_weight': 5},\n",
       "  mean: 0.90809, std: 0.01153, params: {'max_depth': 5, 'min_child_weight': 6}],\n",
       " {'max_depth': 4, 'min_child_weight': 4},\n",
       " 0.9104828873328404)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':[3,4,5],\n",
    " 'min_child_weight':[4,5,6]\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBRegressor( learning_rate =0.05, n_estimators=462, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, verbose=5, iid=False, cv=3)\n",
    "gsearch1.fit(X_train ,y)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] gamma=0.0 .......................................................\n",
      "[CV] .............................. gamma=0.0, score=0.918819 -   2.2s\n",
      "[CV] gamma=0.0 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. gamma=0.0, score=0.898974 -   2.2s\n",
      "[CV] gamma=0.0 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. gamma=0.0, score=0.913656 -   2.2s\n",
      "[CV] gamma=0.1 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    6.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. gamma=0.1, score=0.914284 -   2.7s\n",
      "[CV] gamma=0.1 .......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    9.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. gamma=0.1, score=0.890539 -   2.6s\n",
      "[CV] gamma=0.1 .......................................................\n",
      "[CV] .............................. gamma=0.1, score=0.907126 -   2.7s\n",
      "[CV] gamma=0.2 .......................................................\n",
      "[CV] .............................. gamma=0.2, score=0.904278 -   2.3s\n",
      "[CV] gamma=0.2 .......................................................\n",
      "[CV] .............................. gamma=0.2, score=0.881655 -   2.5s\n",
      "[CV] gamma=0.2 .......................................................\n",
      "[CV] .............................. gamma=0.2, score=0.896865 -   2.3s\n",
      "[CV] gamma=0.3 .......................................................\n",
      "[CV] .............................. gamma=0.3, score=0.901695 -   2.3s\n",
      "[CV] gamma=0.3 .......................................................\n",
      "[CV] .............................. gamma=0.3, score=0.871651 -   2.3s\n",
      "[CV] gamma=0.3 .......................................................\n",
      "[CV] .............................. gamma=0.3, score=0.887053 -   2.3s\n",
      "[CV] gamma=0.4 .......................................................\n",
      "[CV] .............................. gamma=0.4, score=0.895733 -   2.3s\n",
      "[CV] gamma=0.4 .......................................................\n",
      "[CV] .............................. gamma=0.4, score=0.864207 -   2.3s\n",
      "[CV] gamma=0.4 .......................................................\n",
      "[CV] .............................. gamma=0.4, score=0.883584 -   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   35.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.91048, std: 0.00841, params: {'gamma': 0.0},\n",
       "  mean: 0.90398, std: 0.00995, params: {'gamma': 0.10000000000000001},\n",
       "  mean: 0.89427, std: 0.00942, params: {'gamma': 0.20000000000000001},\n",
       "  mean: 0.88680, std: 0.01227, params: {'gamma': 0.30000000000000004},\n",
       "  mean: 0.88117, std: 0.01298, params: {'gamma': 0.40000000000000002}],\n",
       " {'gamma': 0.0},\n",
       " 0.9104828873328404)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    "    'gamma': list(np.arange(0,0.5, 0.1))\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBRegressor( learning_rate =0.05, n_estimators=462, max_depth=4,\n",
    " min_child_weight=4, gamma=0, subsample=0.8, colsample_bytree=0.8, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, verbose=5, iid=False, cv=3)\n",
    "gsearch1.fit(X_train ,y)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "[CV] colsample_bytree=0.5, subsample=0.5 .............................\n",
      "[CV] .... colsample_bytree=0.5, subsample=0.5, score=0.917555 -   1.4s\n",
      "[CV] colsample_bytree=0.5, subsample=0.5 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... colsample_bytree=0.5, subsample=0.5, score=0.896656 -   1.4s\n",
      "[CV] colsample_bytree=0.5, subsample=0.5 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... colsample_bytree=0.5, subsample=0.5, score=0.913689 -   1.4s\n",
      "[CV] colsample_bytree=0.5, subsample=0.6 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    4.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... colsample_bytree=0.5, subsample=0.6, score=0.922177 -   1.4s\n",
      "[CV] colsample_bytree=0.5, subsample=0.6 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    5.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... colsample_bytree=0.5, subsample=0.6, score=0.896234 -   1.4s\n",
      "[CV] colsample_bytree=0.5, subsample=0.6 .............................\n",
      "[CV] .... colsample_bytree=0.5, subsample=0.6, score=0.913313 -   1.4s\n",
      "[CV] colsample_bytree=0.5, subsample=0.7 .............................\n",
      "[CV] .... colsample_bytree=0.5, subsample=0.7, score=0.920769 -   1.5s\n",
      "[CV] colsample_bytree=0.5, subsample=0.7 .............................\n",
      "[CV] .... colsample_bytree=0.5, subsample=0.7, score=0.896633 -   1.5s\n",
      "[CV] colsample_bytree=0.5, subsample=0.7 .............................\n",
      "[CV] .... colsample_bytree=0.5, subsample=0.7, score=0.916130 -   1.5s\n",
      "[CV] colsample_bytree=0.5, subsample=0.8 .............................\n",
      "[CV] .... colsample_bytree=0.5, subsample=0.8, score=0.923602 -   1.5s\n",
      "[CV] colsample_bytree=0.5, subsample=0.8 .............................\n",
      "[CV] .... colsample_bytree=0.5, subsample=0.8, score=0.898536 -   1.5s\n",
      "[CV] colsample_bytree=0.5, subsample=0.8 .............................\n",
      "[CV] .... colsample_bytree=0.5, subsample=0.8, score=0.912380 -   1.5s\n",
      "[CV] colsample_bytree=0.5, subsample=0.9 .............................\n",
      "[CV] .... colsample_bytree=0.5, subsample=0.9, score=0.921008 -   1.5s\n",
      "[CV] colsample_bytree=0.5, subsample=0.9 .............................\n",
      "[CV] .... colsample_bytree=0.5, subsample=0.9, score=0.898506 -   1.5s\n",
      "[CV] colsample_bytree=0.5, subsample=0.9 .............................\n",
      "[CV] .... colsample_bytree=0.5, subsample=0.9, score=0.911277 -   1.5s\n",
      "[CV] colsample_bytree=0.6, subsample=0.5 .............................\n",
      "[CV] .... colsample_bytree=0.6, subsample=0.5, score=0.919394 -   1.6s\n",
      "[CV] colsample_bytree=0.6, subsample=0.5 .............................\n",
      "[CV] .... colsample_bytree=0.6, subsample=0.5, score=0.897855 -   1.6s\n",
      "[CV] colsample_bytree=0.6, subsample=0.5 .............................\n",
      "[CV] .... colsample_bytree=0.6, subsample=0.5, score=0.912933 -   1.6s\n",
      "[CV] colsample_bytree=0.6, subsample=0.6 .............................\n",
      "[CV] .... colsample_bytree=0.6, subsample=0.6, score=0.920087 -   1.9s\n",
      "[CV] colsample_bytree=0.6, subsample=0.6 .............................\n",
      "[CV] .... colsample_bytree=0.6, subsample=0.6, score=0.897965 -   1.8s\n",
      "[CV] colsample_bytree=0.6, subsample=0.6 .............................\n",
      "[CV] .... colsample_bytree=0.6, subsample=0.6, score=0.913319 -   1.7s\n",
      "[CV] colsample_bytree=0.6, subsample=0.7 .............................\n",
      "[CV] .... colsample_bytree=0.6, subsample=0.7, score=0.919609 -   1.7s\n",
      "[CV] colsample_bytree=0.6, subsample=0.7 .............................\n",
      "[CV] .... colsample_bytree=0.6, subsample=0.7, score=0.896472 -   1.7s\n",
      "[CV] colsample_bytree=0.6, subsample=0.7 .............................\n",
      "[CV] .... colsample_bytree=0.6, subsample=0.7, score=0.913451 -   1.7s\n",
      "[CV] colsample_bytree=0.6, subsample=0.8 .............................\n",
      "[CV] .... colsample_bytree=0.6, subsample=0.8, score=0.920977 -   1.7s\n",
      "[CV] colsample_bytree=0.6, subsample=0.8 .............................\n",
      "[CV] .... colsample_bytree=0.6, subsample=0.8, score=0.897612 -   1.8s\n",
      "[CV] colsample_bytree=0.6, subsample=0.8 .............................\n",
      "[CV] .... colsample_bytree=0.6, subsample=0.8, score=0.909918 -   1.8s\n",
      "[CV] colsample_bytree=0.6, subsample=0.9 .............................\n",
      "[CV] .... colsample_bytree=0.6, subsample=0.9, score=0.920497 -   1.8s\n",
      "[CV] colsample_bytree=0.6, subsample=0.9 .............................\n",
      "[CV] .... colsample_bytree=0.6, subsample=0.9, score=0.896427 -   1.8s\n",
      "[CV] colsample_bytree=0.6, subsample=0.9 .............................\n",
      "[CV] .... colsample_bytree=0.6, subsample=0.9, score=0.912262 -   1.8s\n",
      "[CV] colsample_bytree=0.7, subsample=0.5 .............................\n",
      "[CV] .... colsample_bytree=0.7, subsample=0.5, score=0.919567 -   1.9s\n",
      "[CV] colsample_bytree=0.7, subsample=0.5 .............................\n",
      "[CV] .... colsample_bytree=0.7, subsample=0.5, score=0.899495 -   2.6s\n",
      "[CV] colsample_bytree=0.7, subsample=0.5 .............................\n",
      "[CV] .... colsample_bytree=0.7, subsample=0.5, score=0.912125 -   2.6s\n",
      "[CV] colsample_bytree=0.7, subsample=0.6 .............................\n",
      "[CV] .... colsample_bytree=0.7, subsample=0.6, score=0.919528 -   2.6s\n",
      "[CV] colsample_bytree=0.7, subsample=0.6 .............................\n",
      "[CV] .... colsample_bytree=0.7, subsample=0.6, score=0.900133 -   2.5s\n",
      "[CV] colsample_bytree=0.7, subsample=0.6 .............................\n",
      "[CV] .... colsample_bytree=0.7, subsample=0.6, score=0.911263 -   2.5s\n",
      "[CV] colsample_bytree=0.7, subsample=0.7 .............................\n",
      "[CV] .... colsample_bytree=0.7, subsample=0.7, score=0.919625 -   2.5s\n",
      "[CV] colsample_bytree=0.7, subsample=0.7 .............................\n",
      "[CV] .... colsample_bytree=0.7, subsample=0.7, score=0.896435 -   2.7s\n",
      "[CV] colsample_bytree=0.7, subsample=0.7 .............................\n",
      "[CV] .... colsample_bytree=0.7, subsample=0.7, score=0.911395 -   2.4s\n",
      "[CV] colsample_bytree=0.7, subsample=0.8 .............................\n",
      "[CV] .... colsample_bytree=0.7, subsample=0.8, score=0.919043 -   2.4s\n",
      "[CV] colsample_bytree=0.7, subsample=0.8 .............................\n",
      "[CV] .... colsample_bytree=0.7, subsample=0.8, score=0.898125 -   2.4s\n",
      "[CV] colsample_bytree=0.7, subsample=0.8 .............................\n",
      "[CV] .... colsample_bytree=0.7, subsample=0.8, score=0.913272 -   2.3s\n",
      "[CV] colsample_bytree=0.7, subsample=0.9 .............................\n",
      "[CV] .... colsample_bytree=0.7, subsample=0.9, score=0.917841 -   2.3s\n",
      "[CV] colsample_bytree=0.7, subsample=0.9 .............................\n",
      "[CV] .... colsample_bytree=0.7, subsample=0.9, score=0.897667 -   2.3s\n",
      "[CV] colsample_bytree=0.7, subsample=0.9 .............................\n",
      "[CV] .... colsample_bytree=0.7, subsample=0.9, score=0.913873 -   2.2s\n",
      "[CV] colsample_bytree=0.8, subsample=0.5 .............................\n",
      "[CV] .... colsample_bytree=0.8, subsample=0.5, score=0.922642 -   2.3s\n",
      "[CV] colsample_bytree=0.8, subsample=0.5 .............................\n",
      "[CV] .... colsample_bytree=0.8, subsample=0.5, score=0.899661 -   2.2s\n",
      "[CV] colsample_bytree=0.8, subsample=0.5 .............................\n",
      "[CV] .... colsample_bytree=0.8, subsample=0.5, score=0.910349 -   2.2s\n",
      "[CV] colsample_bytree=0.8, subsample=0.6 .............................\n",
      "[CV] .... colsample_bytree=0.8, subsample=0.6, score=0.918330 -   2.4s\n",
      "[CV] colsample_bytree=0.8, subsample=0.6 .............................\n",
      "[CV] .... colsample_bytree=0.8, subsample=0.6, score=0.899645 -   2.3s\n",
      "[CV] colsample_bytree=0.8, subsample=0.6 .............................\n",
      "[CV] .... colsample_bytree=0.8, subsample=0.6, score=0.914545 -   2.3s\n",
      "[CV] colsample_bytree=0.8, subsample=0.7 .............................\n",
      "[CV] .... colsample_bytree=0.8, subsample=0.7, score=0.917660 -   2.3s\n",
      "[CV] colsample_bytree=0.8, subsample=0.7 .............................\n",
      "[CV] .... colsample_bytree=0.8, subsample=0.7, score=0.896863 -   2.3s\n",
      "[CV] colsample_bytree=0.8, subsample=0.7 .............................\n",
      "[CV] .... colsample_bytree=0.8, subsample=0.7, score=0.914749 -   2.3s\n",
      "[CV] colsample_bytree=0.8, subsample=0.8 .............................\n",
      "[CV] .... colsample_bytree=0.8, subsample=0.8, score=0.918819 -   2.3s\n",
      "[CV] colsample_bytree=0.8, subsample=0.8 .............................\n",
      "[CV] .... colsample_bytree=0.8, subsample=0.8, score=0.898974 -   2.3s\n",
      "[CV] colsample_bytree=0.8, subsample=0.8 .............................\n",
      "[CV] .... colsample_bytree=0.8, subsample=0.8, score=0.913656 -   2.3s\n",
      "[CV] colsample_bytree=0.8, subsample=0.9 .............................\n",
      "[CV] .... colsample_bytree=0.8, subsample=0.9, score=0.917326 -   2.3s\n",
      "[CV] colsample_bytree=0.8, subsample=0.9 .............................\n",
      "[CV] .... colsample_bytree=0.8, subsample=0.9, score=0.895142 -   2.3s\n",
      "[CV] colsample_bytree=0.8, subsample=0.9 .............................\n",
      "[CV] .... colsample_bytree=0.8, subsample=0.9, score=0.904787 -   2.3s\n",
      "[CV] colsample_bytree=0.9, subsample=0.5 .............................\n",
      "[CV] .... colsample_bytree=0.9, subsample=0.5, score=0.921095 -   2.3s\n",
      "[CV] colsample_bytree=0.9, subsample=0.5 .............................\n",
      "[CV] .... colsample_bytree=0.9, subsample=0.5, score=0.900887 -   2.3s\n",
      "[CV] colsample_bytree=0.9, subsample=0.5 .............................\n",
      "[CV] .... colsample_bytree=0.9, subsample=0.5, score=0.909016 -   2.3s\n",
      "[CV] colsample_bytree=0.9, subsample=0.6 .............................\n",
      "[CV] .... colsample_bytree=0.9, subsample=0.6, score=0.915190 -   2.4s\n",
      "[CV] colsample_bytree=0.9, subsample=0.6 .............................\n",
      "[CV] .... colsample_bytree=0.9, subsample=0.6, score=0.898070 -   2.4s\n",
      "[CV] colsample_bytree=0.9, subsample=0.6 .............................\n",
      "[CV] .... colsample_bytree=0.9, subsample=0.6, score=0.912223 -   2.4s\n",
      "[CV] colsample_bytree=0.9, subsample=0.7 .............................\n",
      "[CV] .... colsample_bytree=0.9, subsample=0.7, score=0.918735 -   4.0s\n",
      "[CV] colsample_bytree=0.9, subsample=0.7 .............................\n",
      "[CV] .... colsample_bytree=0.9, subsample=0.7, score=0.896717 -   3.9s\n",
      "[CV] colsample_bytree=0.9, subsample=0.7 .............................\n",
      "[CV] .... colsample_bytree=0.9, subsample=0.7, score=0.912672 -   3.9s\n",
      "[CV] colsample_bytree=0.9, subsample=0.8 .............................\n",
      "[CV] .... colsample_bytree=0.9, subsample=0.8, score=0.920996 -   3.3s\n",
      "[CV] colsample_bytree=0.9, subsample=0.8 .............................\n",
      "[CV] .... colsample_bytree=0.9, subsample=0.8, score=0.899268 -   3.2s\n",
      "[CV] colsample_bytree=0.9, subsample=0.8 .............................\n",
      "[CV] .... colsample_bytree=0.9, subsample=0.8, score=0.913529 -   2.9s\n",
      "[CV] colsample_bytree=0.9, subsample=0.9 .............................\n",
      "[CV] .... colsample_bytree=0.9, subsample=0.9, score=0.919111 -   3.8s\n",
      "[CV] colsample_bytree=0.9, subsample=0.9 .............................\n",
      "[CV] .... colsample_bytree=0.9, subsample=0.9, score=0.895904 -   3.1s\n",
      "[CV] colsample_bytree=0.9, subsample=0.9 .............................\n",
      "[CV] .... colsample_bytree=0.9, subsample=0.9, score=0.907134 -   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.90930, std: 0.00908, params: {'colsample_bytree': 0.5, 'subsample': 0.5},\n",
       "  mean: 0.91057, std: 0.01077, params: {'colsample_bytree': 0.5, 'subsample': 0.59999999999999998},\n",
       "  mean: 0.91118, std: 0.01046, params: {'colsample_bytree': 0.5, 'subsample': 0.69999999999999996},\n",
       "  mean: 0.91151, std: 0.01025, params: {'colsample_bytree': 0.5, 'subsample': 0.79999999999999993},\n",
       "  mean: 0.91026, std: 0.00921, params: {'colsample_bytree': 0.5, 'subsample': 0.89999999999999991},\n",
       "  mean: 0.91006, std: 0.00902, params: {'colsample_bytree': 0.59999999999999998, 'subsample': 0.5},\n",
       "  mean: 0.91046, std: 0.00926, params: {'colsample_bytree': 0.59999999999999998, 'subsample': 0.59999999999999998},\n",
       "  mean: 0.90984, std: 0.00978, params: {'colsample_bytree': 0.59999999999999998, 'subsample': 0.69999999999999996},\n",
       "  mean: 0.90950, std: 0.00954, params: {'colsample_bytree': 0.59999999999999998, 'subsample': 0.79999999999999993},\n",
       "  mean: 0.90973, std: 0.00999, params: {'colsample_bytree': 0.59999999999999998, 'subsample': 0.89999999999999991},\n",
       "  mean: 0.91040, std: 0.00829, params: {'colsample_bytree': 0.69999999999999996, 'subsample': 0.5},\n",
       "  mean: 0.91031, std: 0.00795, params: {'colsample_bytree': 0.69999999999999996, 'subsample': 0.59999999999999998},\n",
       "  mean: 0.90915, std: 0.00960, params: {'colsample_bytree': 0.69999999999999996, 'subsample': 0.69999999999999996},\n",
       "  mean: 0.91015, std: 0.00882, params: {'colsample_bytree': 0.69999999999999996, 'subsample': 0.79999999999999993},\n",
       "  mean: 0.90979, std: 0.00873, params: {'colsample_bytree': 0.69999999999999996, 'subsample': 0.89999999999999991},\n",
       "  mean: 0.91088, std: 0.00939, params: {'colsample_bytree': 0.79999999999999993, 'subsample': 0.5},\n",
       "  mean: 0.91084, std: 0.00807, params: {'colsample_bytree': 0.79999999999999993, 'subsample': 0.59999999999999998},\n",
       "  mean: 0.90976, std: 0.00919, params: {'colsample_bytree': 0.79999999999999993, 'subsample': 0.69999999999999996},\n",
       "  mean: 0.91048, std: 0.00841, params: {'colsample_bytree': 0.79999999999999993, 'subsample': 0.79999999999999993},\n",
       "  mean: 0.90575, std: 0.00908, params: {'colsample_bytree': 0.79999999999999993, 'subsample': 0.89999999999999991},\n",
       "  mean: 0.91033, std: 0.00830, params: {'colsample_bytree': 0.89999999999999991, 'subsample': 0.5},\n",
       "  mean: 0.90849, std: 0.00747, params: {'colsample_bytree': 0.89999999999999991, 'subsample': 0.59999999999999998},\n",
       "  mean: 0.90937, std: 0.00929, params: {'colsample_bytree': 0.89999999999999991, 'subsample': 0.69999999999999996},\n",
       "  mean: 0.91126, std: 0.00901, params: {'colsample_bytree': 0.89999999999999991, 'subsample': 0.79999999999999993},\n",
       "  mean: 0.90738, std: 0.00948, params: {'colsample_bytree': 0.89999999999999991, 'subsample': 0.89999999999999991}],\n",
       " {'colsample_bytree': 0.5, 'subsample': 0.79999999999999993},\n",
       " 0.911505907199417)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    "    'subsample': list(np.arange(0.5,1, 0.1)),\n",
    "    'colsample_bytree': list(np.arange(0.5,1, 0.1))\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBRegressor( learning_rate =0.05, n_estimators=462, max_depth=4,\n",
    " min_child_weight=4, gamma=0, subsample=0.8, colsample_bytree=0.8, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, verbose=5, iid=False, cv=3)\n",
    "gsearch1.fit(X_train ,y)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] subsample=0.3 ...................................................\n",
      "[CV] .......................... subsample=0.3, score=0.920103 -   1.6s\n",
      "[CV] subsample=0.3 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................... subsample=0.3, score=0.896909 -   1.5s\n",
      "[CV] subsample=0.3 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................... subsample=0.3, score=0.904754 -   1.5s\n",
      "[CV] subsample=0.4 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    4.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................... subsample=0.4, score=0.922256 -   1.8s\n",
      "[CV] subsample=0.4 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    6.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................... subsample=0.4, score=0.901645 -   1.8s\n",
      "[CV] subsample=0.4 ...................................................\n",
      "[CV] .......................... subsample=0.4, score=0.916710 -   2.3s\n",
      "[CV] subsample=0.5 ...................................................\n",
      "[CV] .......................... subsample=0.5, score=0.922642 -   2.1s\n",
      "[CV] subsample=0.5 ...................................................\n",
      "[CV] .......................... subsample=0.5, score=0.899661 -   2.1s\n",
      "[CV] subsample=0.5 ...................................................\n",
      "[CV] .......................... subsample=0.5, score=0.910349 -   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   17.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.90726, std: 0.00963, params: {'subsample': 0.3},\n",
       "  mean: 0.91354, std: 0.00871, params: {'subsample': 0.4},\n",
       "  mean: 0.91088, std: 0.00939, params: {'subsample': 0.5}],\n",
       " {'subsample': 0.4},\n",
       " 0.913537087276096)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    "    'subsample': [0.3, 0.4, 0.5],\n",
    " }\n",
    "gsearch1 = GridSearchCV(estimator = XGBRegressor( learning_rate =0.05, n_estimators=462, max_depth=4,\n",
    " min_child_weight=4, gamma=0, subsample=0.8, colsample_bytree=0.8, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, verbose=5, iid=False, cv=3)\n",
    "gsearch1.fit(X_train ,y)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] reg_alpha=0 .....................................................\n",
      "[CV] ............................ reg_alpha=0, score=0.922256 -   1.9s\n",
      "[CV] reg_alpha=0 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ reg_alpha=0, score=0.901645 -   1.9s\n",
      "[CV] reg_alpha=0 .....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................ reg_alpha=0, score=0.916710 -   1.9s\n",
      "[CV] reg_alpha=0.001 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................ reg_alpha=0.001, score=0.923460 -   2.6s\n",
      "[CV] reg_alpha=0.001 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    8.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................ reg_alpha=0.001, score=0.900612 -   1.9s\n",
      "[CV] reg_alpha=0.001 .................................................\n",
      "[CV] ........................ reg_alpha=0.001, score=0.912397 -   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   12.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.91354, std: 0.00871, params: {'reg_alpha': 0},\n",
       "  mean: 0.91216, std: 0.00933, params: {'reg_alpha': 0.001}],\n",
       " {'reg_alpha': 0},\n",
       " 0.913537087276096)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    "    'reg_alpha': [0, 0.01, 0.1]}\n",
    "gsearch1 = GridSearchCV(estimator = XGBRegressor( learning_rate =0.05, n_estimators=462, max_depth=4,\n",
    " min_child_weight=4, gamma=0, subsample=0.4, colsample_bytree=0.8, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, verbose=5, iid=False, cv=3)\n",
    "\n",
    "gsearch1.fit(X_train ,y)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] reg_lambda=0 ....................................................\n",
      "[CV] ........................... reg_lambda=0, score=0.918201 -   1.9s\n",
      "[CV] reg_lambda=0 ....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................... reg_lambda=0, score=0.895597 -   1.9s\n",
      "[CV] reg_lambda=0 ....................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........................... reg_lambda=0, score=0.905715 -   1.9s\n",
      "[CV] reg_lambda=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... reg_lambda=0.0001, score=0.917305 -   2.5s\n",
      "[CV] reg_lambda=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    8.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... reg_lambda=0.0001, score=0.896993 -   2.6s\n",
      "[CV] reg_lambda=0.0001 ...............................................\n",
      "[CV] ...................... reg_lambda=0.0001, score=0.904833 -   2.0s\n",
      "[CV] reg_lambda=0.01 .................................................\n",
      "[CV] ........................ reg_lambda=0.01, score=0.917057 -   1.9s\n",
      "[CV] reg_lambda=0.01 .................................................\n",
      "[CV] ........................ reg_lambda=0.01, score=0.895686 -   2.0s\n",
      "[CV] reg_lambda=0.01 .................................................\n",
      "[CV] ........................ reg_lambda=0.01, score=0.908541 -   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   18.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.90650, std: 0.00925, params: {'reg_lambda': 0},\n",
       "  mean: 0.90638, std: 0.00836, params: {'reg_lambda': 0.0001},\n",
       "  mean: 0.90709, std: 0.00878, params: {'reg_lambda': 0.01}],\n",
       " {'reg_lambda': 0.01},\n",
       " 0.907094645606301)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    "    'reg_lambda': [0, 0.0001, 0.01]}\n",
    "gsearch1 = GridSearchCV(estimator = XGBRegressor( learning_rate =0.05, n_estimators=462, max_depth=4,\n",
    " min_child_weight=4, gamma=0, subsample=0.4, colsample_bytree=0.8, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, verbose=5, iid=False, cv=3)\n",
    "gsearch1.fit(X_train ,y)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] colsample_bylevel=0.5 ...........................................\n",
      "[CV] .................. colsample_bylevel=0.5, score=0.921404 -   1.1s\n",
      "[CV] colsample_bylevel=0.5 ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. colsample_bylevel=0.5, score=0.898123 -   1.6s\n",
      "[CV] colsample_bylevel=0.5 ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. colsample_bylevel=0.5, score=0.910604 -   1.9s\n",
      "[CV] colsample_bylevel=0.6 ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    4.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. colsample_bylevel=0.6, score=0.917243 -   2.0s\n",
      "[CV] colsample_bylevel=0.6 ...........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    6.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. colsample_bylevel=0.6, score=0.899631 -   1.3s\n",
      "[CV] colsample_bylevel=0.6 ...........................................\n",
      "[CV] .................. colsample_bylevel=0.6, score=0.911289 -   1.4s\n",
      "[CV] colsample_bylevel=0.7 ...........................................\n",
      "[CV] .................. colsample_bylevel=0.7, score=0.919125 -   1.5s\n",
      "[CV] colsample_bylevel=0.7 ...........................................\n",
      "[CV] .................. colsample_bylevel=0.7, score=0.902563 -   1.5s\n",
      "[CV] colsample_bylevel=0.7 ...........................................\n",
      "[CV] .................. colsample_bylevel=0.7, score=0.911312 -   1.4s\n",
      "[CV] colsample_bylevel=0.8 ...........................................\n",
      "[CV] .................. colsample_bylevel=0.8, score=0.917250 -   2.2s\n",
      "[CV] colsample_bylevel=0.8 ...........................................\n",
      "[CV] .................. colsample_bylevel=0.8, score=0.901100 -   2.0s\n",
      "[CV] colsample_bylevel=0.8 ...........................................\n",
      "[CV] .................. colsample_bylevel=0.8, score=0.908094 -   1.9s\n",
      "[CV] colsample_bylevel=0.9 ...........................................\n",
      "[CV] .................. colsample_bylevel=0.9, score=0.921166 -   2.1s\n",
      "[CV] colsample_bylevel=0.9 ...........................................\n",
      "[CV] .................. colsample_bylevel=0.9, score=0.895797 -   1.7s\n",
      "[CV] colsample_bylevel=0.9 ...........................................\n",
      "[CV] .................. colsample_bylevel=0.9, score=0.916083 -   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   25.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.91004, std: 0.00951, params: {'colsample_bylevel': 0.5},\n",
       "  mean: 0.90939, std: 0.00731, params: {'colsample_bylevel': 0.59999999999999998},\n",
       "  mean: 0.91100, std: 0.00676, params: {'colsample_bylevel': 0.69999999999999996},\n",
       "  mean: 0.90881, std: 0.00661, params: {'colsample_bylevel': 0.79999999999999993},\n",
       "  mean: 0.91102, std: 0.01096, params: {'colsample_bylevel': 0.89999999999999991}],\n",
       " {'colsample_bylevel': 0.89999999999999991},\n",
       " 0.9110152921314851)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    "    'colsample_bylevel': list(np.arange(0.5, 1.0, 0.1))}\n",
    "gsearch1 = GridSearchCV(estimator = XGBRegressor( learning_rate =0.05, n_estimators=462, max_depth=4,\n",
    " min_child_weight=4, gamma=0, subsample=0.4, colsample_bytree=0.8, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, verbose=5, iid=False, cv=3)\n",
    "gsearch1.fit(X_train ,y)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.416143</td>\n",
       "      <td>0.007816</td>\n",
       "      <td>11.416146</td>\n",
       "      <td>0.003969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.302526</td>\n",
       "      <td>0.007835</td>\n",
       "      <td>11.302528</td>\n",
       "      <td>0.003945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.189959</td>\n",
       "      <td>0.007974</td>\n",
       "      <td>11.189961</td>\n",
       "      <td>0.003801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.078519</td>\n",
       "      <td>0.008041</td>\n",
       "      <td>11.078520</td>\n",
       "      <td>0.003727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.968146</td>\n",
       "      <td>0.008021</td>\n",
       "      <td>10.968148</td>\n",
       "      <td>0.003749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.858871</td>\n",
       "      <td>0.007923</td>\n",
       "      <td>10.858873</td>\n",
       "      <td>0.003837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.750753</td>\n",
       "      <td>0.008026</td>\n",
       "      <td>10.750755</td>\n",
       "      <td>0.003729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.643711</td>\n",
       "      <td>0.008134</td>\n",
       "      <td>10.643713</td>\n",
       "      <td>0.003622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.537756</td>\n",
       "      <td>0.008308</td>\n",
       "      <td>10.537758</td>\n",
       "      <td>0.003448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.432739</td>\n",
       "      <td>0.008280</td>\n",
       "      <td>10.432742</td>\n",
       "      <td>0.003467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.328752</td>\n",
       "      <td>0.008339</td>\n",
       "      <td>10.328754</td>\n",
       "      <td>0.003397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.225945</td>\n",
       "      <td>0.008270</td>\n",
       "      <td>10.225947</td>\n",
       "      <td>0.003457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.124155</td>\n",
       "      <td>0.008390</td>\n",
       "      <td>10.124158</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.023435</td>\n",
       "      <td>0.008486</td>\n",
       "      <td>10.023437</td>\n",
       "      <td>0.003229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.923617</td>\n",
       "      <td>0.008450</td>\n",
       "      <td>9.923620</td>\n",
       "      <td>0.003260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.824776</td>\n",
       "      <td>0.008633</td>\n",
       "      <td>9.824778</td>\n",
       "      <td>0.003071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9.726988</td>\n",
       "      <td>0.008709</td>\n",
       "      <td>9.726991</td>\n",
       "      <td>0.002991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.630146</td>\n",
       "      <td>0.008628</td>\n",
       "      <td>9.630148</td>\n",
       "      <td>0.003064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.534164</td>\n",
       "      <td>0.008704</td>\n",
       "      <td>9.534166</td>\n",
       "      <td>0.002986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.439096</td>\n",
       "      <td>0.009039</td>\n",
       "      <td>9.439099</td>\n",
       "      <td>0.002650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.345100</td>\n",
       "      <td>0.009342</td>\n",
       "      <td>9.345103</td>\n",
       "      <td>0.002343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.251987</td>\n",
       "      <td>0.009409</td>\n",
       "      <td>9.251990</td>\n",
       "      <td>0.002265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9.159783</td>\n",
       "      <td>0.009463</td>\n",
       "      <td>9.159786</td>\n",
       "      <td>0.002205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9.068579</td>\n",
       "      <td>0.009586</td>\n",
       "      <td>9.068582</td>\n",
       "      <td>0.002078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8.978279</td>\n",
       "      <td>0.009613</td>\n",
       "      <td>8.978281</td>\n",
       "      <td>0.002045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8.888943</td>\n",
       "      <td>0.009691</td>\n",
       "      <td>8.888945</td>\n",
       "      <td>0.001960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8.800476</td>\n",
       "      <td>0.009718</td>\n",
       "      <td>8.800478</td>\n",
       "      <td>0.001940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8.712829</td>\n",
       "      <td>0.009755</td>\n",
       "      <td>8.712831</td>\n",
       "      <td>0.001883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8.626163</td>\n",
       "      <td>0.009741</td>\n",
       "      <td>8.626165</td>\n",
       "      <td>0.001889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8.540268</td>\n",
       "      <td>0.009870</td>\n",
       "      <td>8.540270</td>\n",
       "      <td>0.001747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>0.118953</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>0.065784</td>\n",
       "      <td>0.002609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>0.118948</td>\n",
       "      <td>0.005167</td>\n",
       "      <td>0.065748</td>\n",
       "      <td>0.002603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>0.118953</td>\n",
       "      <td>0.005167</td>\n",
       "      <td>0.065735</td>\n",
       "      <td>0.002606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>0.118963</td>\n",
       "      <td>0.005174</td>\n",
       "      <td>0.065704</td>\n",
       "      <td>0.002614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>0.118962</td>\n",
       "      <td>0.005166</td>\n",
       "      <td>0.065687</td>\n",
       "      <td>0.002612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>0.118961</td>\n",
       "      <td>0.005159</td>\n",
       "      <td>0.065660</td>\n",
       "      <td>0.002624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>0.118957</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>0.065628</td>\n",
       "      <td>0.002630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>0.118967</td>\n",
       "      <td>0.005166</td>\n",
       "      <td>0.065598</td>\n",
       "      <td>0.002626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>0.118963</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>0.065573</td>\n",
       "      <td>0.002624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>0.118949</td>\n",
       "      <td>0.005170</td>\n",
       "      <td>0.065534</td>\n",
       "      <td>0.002614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>0.118950</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>0.065509</td>\n",
       "      <td>0.002622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>0.118943</td>\n",
       "      <td>0.005181</td>\n",
       "      <td>0.065474</td>\n",
       "      <td>0.002613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>0.118930</td>\n",
       "      <td>0.005185</td>\n",
       "      <td>0.065452</td>\n",
       "      <td>0.002608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>0.118945</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>0.065426</td>\n",
       "      <td>0.002599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>0.118945</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>0.065393</td>\n",
       "      <td>0.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>0.118954</td>\n",
       "      <td>0.005182</td>\n",
       "      <td>0.065371</td>\n",
       "      <td>0.002606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>0.118963</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.065342</td>\n",
       "      <td>0.002617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>0.118955</td>\n",
       "      <td>0.005175</td>\n",
       "      <td>0.065321</td>\n",
       "      <td>0.002605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>0.118962</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.065290</td>\n",
       "      <td>0.002603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>0.118944</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.065263</td>\n",
       "      <td>0.002614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>0.118947</td>\n",
       "      <td>0.005154</td>\n",
       "      <td>0.065241</td>\n",
       "      <td>0.002615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>0.118950</td>\n",
       "      <td>0.005148</td>\n",
       "      <td>0.065213</td>\n",
       "      <td>0.002614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>0.118953</td>\n",
       "      <td>0.005145</td>\n",
       "      <td>0.065190</td>\n",
       "      <td>0.002624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>0.118967</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>0.065161</td>\n",
       "      <td>0.002615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>0.118965</td>\n",
       "      <td>0.005156</td>\n",
       "      <td>0.065137</td>\n",
       "      <td>0.002617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>0.118952</td>\n",
       "      <td>0.005148</td>\n",
       "      <td>0.065115</td>\n",
       "      <td>0.002622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>0.118952</td>\n",
       "      <td>0.005148</td>\n",
       "      <td>0.065087</td>\n",
       "      <td>0.002621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>0.118950</td>\n",
       "      <td>0.005144</td>\n",
       "      <td>0.065051</td>\n",
       "      <td>0.002622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>0.118943</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.065031</td>\n",
       "      <td>0.002616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>0.118927</td>\n",
       "      <td>0.005144</td>\n",
       "      <td>0.065003</td>\n",
       "      <td>0.002622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1335 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      test-rmse-mean  test-rmse-std  train-rmse-mean  train-rmse-std\n",
       "0          11.416143       0.007816        11.416146        0.003969\n",
       "1          11.302526       0.007835        11.302528        0.003945\n",
       "2          11.189959       0.007974        11.189961        0.003801\n",
       "3          11.078519       0.008041        11.078520        0.003727\n",
       "4          10.968146       0.008021        10.968148        0.003749\n",
       "5          10.858871       0.007923        10.858873        0.003837\n",
       "6          10.750753       0.008026        10.750755        0.003729\n",
       "7          10.643711       0.008134        10.643713        0.003622\n",
       "8          10.537756       0.008308        10.537758        0.003448\n",
       "9          10.432739       0.008280        10.432742        0.003467\n",
       "10         10.328752       0.008339        10.328754        0.003397\n",
       "11         10.225945       0.008270        10.225947        0.003457\n",
       "12         10.124155       0.008390        10.124158        0.003333\n",
       "13         10.023435       0.008486        10.023437        0.003229\n",
       "14          9.923617       0.008450         9.923620        0.003260\n",
       "15          9.824776       0.008633         9.824778        0.003071\n",
       "16          9.726988       0.008709         9.726991        0.002991\n",
       "17          9.630146       0.008628         9.630148        0.003064\n",
       "18          9.534164       0.008704         9.534166        0.002986\n",
       "19          9.439096       0.009039         9.439099        0.002650\n",
       "20          9.345100       0.009342         9.345103        0.002343\n",
       "21          9.251987       0.009409         9.251990        0.002265\n",
       "22          9.159783       0.009463         9.159786        0.002205\n",
       "23          9.068579       0.009586         9.068582        0.002078\n",
       "24          8.978279       0.009613         8.978281        0.002045\n",
       "25          8.888943       0.009691         8.888945        0.001960\n",
       "26          8.800476       0.009718         8.800478        0.001940\n",
       "27          8.712829       0.009755         8.712831        0.001883\n",
       "28          8.626163       0.009741         8.626165        0.001889\n",
       "29          8.540268       0.009870         8.540270        0.001747\n",
       "...              ...            ...              ...             ...\n",
       "1305        0.118953       0.005164         0.065784        0.002609\n",
       "1306        0.118948       0.005167         0.065748        0.002603\n",
       "1307        0.118953       0.005167         0.065735        0.002606\n",
       "1308        0.118963       0.005174         0.065704        0.002614\n",
       "1309        0.118962       0.005166         0.065687        0.002612\n",
       "1310        0.118961       0.005159         0.065660        0.002624\n",
       "1311        0.118957       0.005162         0.065628        0.002630\n",
       "1312        0.118967       0.005166         0.065598        0.002626\n",
       "1313        0.118963       0.005161         0.065573        0.002624\n",
       "1314        0.118949       0.005170         0.065534        0.002614\n",
       "1315        0.118950       0.005178         0.065509        0.002622\n",
       "1316        0.118943       0.005181         0.065474        0.002613\n",
       "1317        0.118930       0.005185         0.065452        0.002608\n",
       "1318        0.118945       0.005191         0.065426        0.002599\n",
       "1319        0.118945       0.005178         0.065393        0.002600\n",
       "1320        0.118954       0.005182         0.065371        0.002606\n",
       "1321        0.118963       0.005186         0.065342        0.002617\n",
       "1322        0.118955       0.005175         0.065321        0.002605\n",
       "1323        0.118962       0.005172         0.065290        0.002603\n",
       "1324        0.118944       0.005169         0.065263        0.002614\n",
       "1325        0.118947       0.005154         0.065241        0.002615\n",
       "1326        0.118950       0.005148         0.065213        0.002614\n",
       "1327        0.118953       0.005145         0.065190        0.002624\n",
       "1328        0.118967       0.005150         0.065161        0.002615\n",
       "1329        0.118965       0.005156         0.065137        0.002617\n",
       "1330        0.118952       0.005148         0.065115        0.002622\n",
       "1331        0.118952       0.005148         0.065087        0.002621\n",
       "1332        0.118950       0.005144         0.065051        0.002622\n",
       "1333        0.118943       0.005142         0.065031        0.002616\n",
       "1334        0.118927       0.005144         0.065003        0.002622\n",
       "\n",
       "[1335 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'eta':0.01, 'max_depth':4, 'min_child_weight':4, 'subsample':0.4, 'colsample_bytree':0.8, 'scale_pos_weight':1}\n",
    "num_rounds = 1500\n",
    "early_stopping_rounds = 20\n",
    "xgb.cv(params, dtr,num_rounds, early_stopping_rounds=early_stopping_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'eta':0.01, 'max_depth':4, 'min_child_weight':4, 'subsample':0.4, 'colsample_bytree':0.8, 'scale_pos_weight':1}\n",
    "num_rounds = 1334\n",
    "bst = xgb.train(params, dtr,num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_preds = bst.predict(dtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 200653.171875,  172396.484375,  209047.46875 , ...,  254594.078125,\n",
       "        138676.28125 ,  142848.640625], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expm1(train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('xgb_train_preds.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(train_preds, pickle_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit our tuned model on all the data prior to submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on the test set and undo our log transform so that the values will be on their original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_clean.csv', dtype={'MSSubClass': str})\n",
    "test_ids = test.Id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_preds_to_save = bst.predict(xgb.DMatrix(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('xgb_test_preds.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(test_preds_to_save, pickle_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('xgb_train_preds.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(train_preds, pickle_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = np.expm1(bst.predict(xgb.DMatrix(X_test)))\n",
    "solution = pd.DataFrame({\"id\":test_ids, \"SalePrice\":preds}, columns=['id', 'SalePrice'])\n",
    "\n",
    "solution.to_csv(\"xgb.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one scores .12046"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the model so we can use it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(bestLassoEst, 'poly_features_35_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
